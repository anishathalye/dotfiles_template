[ -f ~/.env ] && source ~/.env
[ -f ~/.env_private ] && source ~/.env_private

unalias  fd >/dev/null 2>/dev/null # in order to use https://github.com/sharkdp/fd

##########################
# DOTFILES UPDATE
##########################
alias dotfiles="cd $DOTFILES_PATH"
# update dotfiles
alias dotf_update='dotfiles && git pull && bash install; cd -'

##########################
# UPDATE AppImages
##########################
alias update_nextcloud="wget https://download.nextcloud.com/desktop/releases/Linux/latest -O $HOME/bin/Nextcloud.AppImage && chmod +x $HOME/bin/*.AppImage"
alias update_joplin='curl -s https://api.github.com/repos/laurent22/joplin/releases/latest | grep "browser_download_url.*AppImage" | cut -d : -f 2,3 | tr -d \" | wget -qi - -O $HOME/bin/Joplin.AppImage && chmod +x $HOME/bin/*.AppImage'
alias update_etcher='curl -s https://api.github.com/repos/balena-io/etcher/releases/latest | grep "browser_download_url.*x64.AppImage" | cut -d : -f 2,3 | tr -d \" | wget -qi - -O $HOME/bin/balenaEtcher.AppImage && chmod +x $HOME/bin/*.AppImage'
alias update_shotcut='curl -s https://api.github.com/repos/mltframework/shotcut/releases/latest | grep "browser_download_url.*AppImage" | cut -d : -f 2,3 | tr -d \" | wget -qi - -O $HOME/bin/Shotcut.AppImage && chmod +x $HOME/bin/*.AppImage'
alias update_appimages='update_nextcloud; update_joplin; update_etcher; update_shotcut'

alias shotcut='Shotcut.AppImage --QT_SCALE_FACTOR 1'
alias Shotcut='shotcut'

##########################
# ls and cd aliases
##########################
# quick way to get out of current directory
alias ..='cd ..'
alias ...='cd ../../../'
alias ....='cd ../../../../'
alias .....='cd ../../../../'
alias .4='cd ../../../../'
alias .5='cd ../../../../..'
alias cc='ls -f | wc -l' # ls -f does not stat() and makes it faster

path_to_lsd=$(which lsd 2>/dev/null)
if [ -x "$path_to_lsd" ] ; then
    alias ls='lsd'
    alias l='ls -l'
    alias ll='ls -l'
    alias la='ls -a'
    alias lla='ls -la'
    alias lt='ls --tree'
fi

alias ls_recur="find . -type f -exec ls -l {} \; 2> /dev/null | sort -t' ' -k +6,6 -k +7,7"


##########################
# CHEF cooking
##########################
alias chef_cd="cd $CHEF_DIR"
alias talend="chef_cd && ./bin/talend7-pipeline.sh"
alias chef_private_cd="cd $CHEF_DIR/../chef-private"
alias chef_imos="chef_cd && rm -f private; ln -s ../chef-private private"
alias chef_po_box_start="chef_sample &&  ./bin/pipeline-box.sh && vagrant ssh po"
alias chef_provision_laptop_from_remote='cd $DOTFILES_PATH; git reset-branch-like-remote; cd $GITHUB_DIR/chef_laptop; git reset-branch-like-remote; $GITHUB_DIR/chef_laptop/install.sh;'
alias chef_provision_laptop_from_local='cd $GITHUB_DIR/chef_laptop; $GITHUB_DIR/chef_laptop/install.sh'
alias chef_provision_po="chef_cd && vagrant provision po"
alias chef_sample="chef_cd && rm -f private; ln -s private-sample private"


##########################
# IMOS related - pipeline 
##########################
# pipeline 
alias pipe_tasklog_tailf='var=$(find /mnt/ebs/log/pipeline/process/ -type f -name "task*.log" | fzf) && tail -f $var'
alias pipe_alllog_tailf='var=$(find /mnt/ebs/log/pipeline -type f -name "*.log" | fzf) && tail -f $var'
alias pipe_ls_error='var=$(find $ERROR_DIR -maxdepth 1 -type d | fzf) && ls $var'
alias pipe_cd_error='var=$(find $ERROR_DIR -maxdepth 1 -type d | fzf) && cd $var'

alias talend_cd='var=$(find /mnt/ebs/talend/jobs -maxdepth 1 -type d | fzf) && cd $var'

# retrieve specific log output for failed file in pipeline
# $1 error file path
pipe_file_error_output(){
    local file_input=$1;

    local uuid
    uuid=`echo "$file_input" | grep -o -E '[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}'`

    if [ -z "$uuid" ]
        then
        echo "no uuid found in filename"
        return 1
    fi

    local pipeline_name
    pipeline_name=`basename $(dirname $(readlink -f $file_input))`

    grep $uuid /mnt/ebs/log/pipeline/process/tasks.$pipeline_name.log
}

# compliance checker running the cf check
# $1 cf version
# $2 netcdf file
cc_cf() {
    local cf_version=$1; shift
    local ncf=$1; shift
    [ -f /mnt/ebs/pipeline/bin/activate ] && . /mnt/ebs/pipeline/bin/activate
    compliance-checker -t=cf:$cf_version $ncf
}

# compliance checker running the cf 1.6 check
# $1 netcdf file
cc_cf_1.6() {
    local ncf=$1; shift
    cc_cf 1.6 $ncf
}

# compliance checker running the latest cf check
# $1 netcdf file
cc_cf_latest() {
    local ncf=$1; shift
    cc_cf latest $ncf
}

# compliance checker running the imos check
# $1 netcdf file
cc_imos() {
    local ncf=$1; shift
    [ -f /mnt/ebs/pipeline/bin/activate ] && . /mnt/ebs/pipeline/bin/activate
    compliance-checker -t=imos $ncf
}


##########################
# Various
##########################
alias project_officer_user='sudo -u projectofficer -s'
alias rsrc='source ~/.bashrc'
alias clear_tmp="find /tmp -mtime +1 -and -not -exec fuser -s {} ';' -and -exec rm -Rf {} ';'"
alias display_docked=". $HOME/.screenlayout/work_screen2_thunder.sh && mouse_setting.sh"
alias work_workspace='display_docked & tmux'
alias fzfp="fzf -m --preview 'head -100 {}'"
alias g='git'
alias geoserver_cd="cd $CHEF_DIR/src/geoserver"
alias github_cd="cd $GITHUB_DIR"
alias sublime='subl'
alias grep='grep --color=auto'
alias trim="sed 's/^ *//;s/ *$//'"
alias egrep='egrep --color=auto'
alias fgrep='fgrep --color=auto'
alias copy='| xclip -sel clip'
alias automount='udiskie &'

alias irssi='screen irssi'
alias tmux_start="[[ ! $TERM =~ screen ]] && [ -z $TMUX ] && exec tmux -2 attach"
function x(){
    if [ -f $1 ] ; then
            case $1 in
                    *.tar.bz2)   tar xvjf $1    ;;
                    *.tar.gz)    tar xvzf $1    ;;
                    *.bz2)       bunzip2 $1     ;;
                    *.rar)       unrar x $1     ;;
                    *.gz)        gunzip $1      ;;
                    *.tar)       tar xvf $1     ;;
                    *.tbz2)      tar xvjf $1    ;;
                    *.tgz)       tar xvzf $1    ;;
                    *.zip)       unzip $1       ;;
                    *.Z)         uncompress $1  ;;
                    *.7z)        7z x $1        ;;
                    *)           echo "Unable to extract '$1'" ;;
            esac
    else
            echo "'$1' is not a valid file"
    fi
}


##########################
# NETWORK
##########################
alias iftop_wlan='iftop -i wlan0'
alias lynx='lynx -cfg=~/.lynx.cfg'
alias elinks_google='elinks www.google.com.au'
alias mac_wlan_random='sudo ifconfig wlp1s0 down && sudo macchanger -r wlp1s0 && sudo ifconfig wlp1s0 up'
alias ports='netstat -tulanp' # open ports
alias ssh-add='ssh-add -t 10h'
alias wifi_restart='sudo systemctl restart wpa_supplicant.service'
alias wifi_connect_to='nmtui'

if command -v dig > /dev/null; then
    alias myip="dig +short myip.opendns.com @resolver1.opendns.com"
    alias mygeo="curl -w \"\\n\" http://api.hackertarget.com/geoip/\?q=\`myip\`"
else
    alias myip="curl ifconfig.me"
fi

# ssh
alias s='var=$(grep -e "^Host " ~/.ssh/config | sed "s#Host ##" | fzf) && ssh $var' # ssh with fzf to list known hosts from ssh/config
[ -f ~/.utas_vpnc.conf ] && alias vpn_utas_connect='sudo vpnc ~/.utas_vpnc.conf --local-port 0' && alias vpn_utas_disconnect='sudo vpnc-disconnect'

alias vpn_bfunk_start='sudo openvpn --cd $DOTFILES_PRIVATE_PATH/openvpn/ --writepid /run/openvpn/home.pid --config bfunk.conf'
alias vpn_evry_start='sudo openvpn --cd $DOTFILES_PRIVATE_PATH/openvpn/ --writepid /run/openvpn/home.pid --config evry.conf'


##########################
# vim nvim alias
##########################
if command -v nvim > /dev/null; then
    alias vim='nvim'
    alias vi='nvim'
    alias v='f -e nvim' # replace default fasd alias from zsh plugin
fi
alias vim_plugin_install='vim +PluginInstall +qall'

if command -v bat > /dev/null; then alias cat="bat -p"; fi



##########################
# timezone
##########################
alias tz_paris='TZ="Europe/Paris" date'
alias tz_hobart='TZ="Australia/Hobart" date'
alias tz_utc='TZ="UTC" date'


##########################
# SYSTEM
##########################
if command -v htop > /dev/null; then alias top='htop'; fi
if command -v dfc > /dev/null; then alias df='dfc'; fi

if command -v ncdu > /dev/null; then
    alias gt5=ncdu
    alias hdd_report=ncdu
fi

alias temperature='sensors;sudo hddtemp /dev/sda'
alias shutdown_now='sudo shutdown -h now'
alias latest_installed_pckg='cat /var/log/apt/history.log | grep "\ install\ "'
alias killall='killall -SIGUSR1'
alias lock_screen='gnome-screensaver-command --lock || xscreensaver-command -lock'

fkill() {
    local pid 
    if [ "$UID" != "0" ]; then
        pid=$(ps -f -u $UID | sed 1d | fzf -m | awk '{print $2}')
    else
        pid=$(ps -ef | sed 1d | fzf -m | awk '{print $2}')
    fi  

    if [ "x$pid" != "x" ]
    then
        echo $pid | xargs kill -${1:-9}
    fi  
}



#########################
# DATABASE
#########################
if command -v pgcli > /dev/null; then
    alias psql=pgcli
fi

DBHOST='2-nec-hob.emii.org.au'
[ -f $HOME/.pgpass ] && alias psql-dbrc="psql -d harvest -h $DBHOST -U `cat $HOME/.pgpass  | grep $DBHOST | cut -d':' -f4`"

DBHOST='dbprod.emii.org.au'
[ -f $HOME/.pgpass ] && alias psql-dbprod="psql -d harvest -h $DBHOST -U `cat $HOME/.pgpass  | grep $DBHOST | cut -d':' -f4`"

DBHOST='10.11.12.13'
[ -f $HOME/.pgpass ] && alias psql-po="psql -d harvest -h $DBHOST -U `cat $HOME/.pgpass  | grep $DBHOST | cut -d':' -f4`"

DBHOST='harvest-db-aodnstack-lbesnard.dev.aodn.org.au'
[ -f $HOME/.pgpass ] && alias psql-pipeline-stack="psql -d harvest -h $DBHOST -U `cat $HOME/.pgpass  | grep $DBHOST | cut -d':' -f4`"




##########################
# file handling
##########################
remove_space_from_filename_recur() {
    find . -depth -name "* *" -execdir rename 's/ /_/g' "{}" \;
}

remove_file_extension() {
    local file="$1"; shift
    mv $file ${file%\.[^.]*}
}



##########################
# NetCDF
##########################
ncdumph() {
    command ncdump -h "$@" | less;
}


###########################
# MUSIC
###########################
alias beet_genre_uniq_update="beet ls -f '\$genre' | sort -u > ~/.beets_genre"
alias split_flac_album='IFS=$(echo -en "\n\b"); for CUE in `find . -type f -name "*.cue"`; do FILE_TO_CONVERT=`basename ${CUE%.*}.flac` && shnsplit -f "$CUE" -t %n-%t -o flac "$FILE_TO_CONVERT" && rm -f "$FILE_TO_CONVERT";done'
alias split_ape_album='IFS=$(echo -en "\n\b"); for CUE in `find . -type f -name "*.cue"`; do FILE_TO_CONVERT=`basename ${CUE%.*}.ape` && shnsplit -f "$CUE" -t %n-%t -o flac "$FILE_TO_CONVERT" && rm -f "$FILE_TO_CONVERT";done'
alias split_wv_album='IFS=$(echo -en "\n\b"); for CUE in `find . -type f -name "*.cue"`; do FILE_TO_CONVERT=`basename ${CUE%.*}.vw` && shnsplit -f "$CUE" -t %n-%t -o flac "$FILE_TO_CONVERT" && rm -f "$FILE_TO_CONVERT";done'
alias music_player='mp3blaster'
alias volume='pavulcontrol'


###########################
# paragliding
###########################
alias flightrecorder='cd $HOME/paragliding ; sudo flightrecorder && chown $USER:$USER *.IGC; rsync -avc $HOME/paragliding/ $HOME/Dropbox/paragliding_igc'
alias igc_viewer='gpligc'
alias riverHeight='python $GITHUB_DIR/River_Height_Tasmania/riverHeight.py && /usr/bin/elinks ~/Dropbox/Public/RiverStatusTasmania.html'
alias gpsdump_flymaster='cd $HOME/Downloads; ./gpsdump -gy -ca0 -lflight'
alias paragliding_create_osm_map='$GITHUB_DIR/OSM_Tile_Download/osm_ogie3d.py'


##############################
# PYTHON
##############################
python_venv_init () {
    local venv_name=$1; shift
    mkdir venv_name && cd venv_name;
    sourve venv/vin/activate
    xargs -a requirements.txt -n 1 pip install
}
alias pip_install_requirements='xargs -a requirements.txt -n 1 pip install'

kill_py () {
    local python_script_name=$1; shift
    kill -9 $(ps aux | grep '[p]ython.*${python_script_name}\.py'| awk '{print $2}')
}


##############################
# COMICS specific functions
##############################
function pdf2cbz(){
    IFS=$(echo -en "\n\b");
    PDF_FILE="$1"; shift;

    PDF_FILE_PATH=`readlink -f "$PDF_FILE"`;
    PDF_FILE_NAME=`basename "$PDF_FILE_PATH"`;
    PDF_FILE_DIRNAME=`dirname "$PDF_FILE_PATH"`;

    temp_dir=`mktemp -d`;

    if command -v pdfimages > /dev/null; then
        pdfimages -j "$PDF_FILE_PATH" $temp_dir/page && \
        zip -jr "${PDF_FILE_PATH%.*}.cbz" $temp_dir/* && \
        mv "$PDF_FILE_PATH" "$PDF_FILE_DIRNAME"/."$PDF_FILE_NAME" && \
        rm -Rf $temp_dir;
    else
        echo "Please install pdfimages package"
    fi
}
alias comic_pdf2cbz='pdf2cbz'


function pdf2cbz_all_files_in_dir() {
    IFS=$(echo -en "\n\b");
    for f in `find . -maxdepth 1 -type f -name '*.pdf' -not -path '*/\.*' -exec readlink -f {} \;`;do
        pdf2cbz "$f";
    done;
}
alias comic_pdf2cbz_all_files_in_dir=pdf2cbz_all_files_in_dir


function dirs2cbz() {
    IFS=$(echo -en "\n\b");
    for dir in `find . -mindepth 1 -type d -not -empty`; do
        if find "$dir" -maxdepth 1 -type f -not -ipath '.*\.cbz' -not -ipath '.*\.cbr' -not  -ipath '.*\.pdf'| read f; then
            zip "$(dirname "$dir")/$(basename "$dir").cbz" "$dir"/* && rm -Rf "$dir" ;*/
        fi;
    done
}
alias comic_dirs2cbz=dirs2cbz


function append_folder_name_as_prefix_to_file(){
    IFS=$(echo -en "\n\b");
    local file="$1"; shift;
    mv "${file}" "${PWD##*/} - ${file}"
}
alias comic_add_serie_name='append_folder_name_as_prefix_to_file'

function cbz2pdf(){
    IFS=$(echo -en "\n\b");
    ARCHIVE_FILE="$1"; shift;

    ARCHIVE_FILE_PATH=`readlink -f "$ARCHIVE_FILE"`;
    ARCHIVE_FILE_NAME=`basename "$ARCHIVE_FILE_PATH"`;
    ARCHIVE_FILE_DIRNAME=`dirname "$ARCHIVEFILE_PATH"`;

    temp_dir=`mktemp -d`;

    if ! command -v dwebp > /dev/null; then
        echo "Please install webp package"
        return 1
    fi

    if command -v convert > /dev/null; then
        unzip -j "$ARCHIVE_FILE_PATH" -d $temp_dir
        find $temp_dir/ -name "*.webp" -exec dwebp {} -o {}.jpg \;
        convert $temp_dir/*.jpg "${ARCHIVE_FILE_PATH%.*}.pdf"

        mv "$ARCHIVE_FILE_PATH" "$ARCHIVE_FILE_DIRNAME"/."$ARCHIVE_FILE_NAME" && \
        rm -Rf $temp_dir;
    else
        echo "Please install imagemagick package"
        return 1
    fi
}
alias comic_cbz2pdf='cbz2pdf'

function comic_repack_corrupt_archive2cbz(){
    IFS=$(echo -en "\n\b");
    ARCHIVE_FILE="$1"; shift;

    ARCHIVE_FILE_PATH=`readlink -f "$ARCHIVE_FILE"`;
    ARCHIVE_FILE_NAME=`basename "$ARCHIVE_FILE_PATH"`;
    ARCHIVE_FILE_DIRNAME=`dirname "$ARCHIVEFILE_PATH"`;

    if ! command -v arepack > /dev/null; then
        echo "Please install atool package"
        return 1
    fi

    arepack "$ARCHIVE_FILE_PATH" "${ARCHIVE_FILE_PATH%.*}.zip"
    mv -f "$ARCHIVE_FILE_PATH" "$ARCHIVE_FILE_DIRNAME"/."$ARCHIVE_FILE_NAME" && \
      mv -f "${ARCHIVE_FILE_PATH%.*}.zip"  "${ARCHIVE_FILE_PATH%.*}.cbz"

    # remove file from archive
    zip -o -d "${ARCHIVE_FILE_PATH%.*}.cbz" \*crg.gif
}


function comic_repack_all_corrupt_archive2cbz(){
    IFS=$(echo -en "\n\b");
    for f in `find . -maxdepth 1 -type f  -not -path '*/\.*' -exec readlink -f {} \;`;do
        comic_repack_corrupt_archive2cbz "$f";
    done;
}

##############################
# docker compose
##############################
alias dcp='docker-compose -f /opt/docker-compose.yml '
alias dcpull='docker-compose -f /opt/docker-compose.yml pull --parallel'
alias dclogs='docker-compose -f /opt/docker-compose.yml logs -tf --tail="50" '
alias dtail='docker logs -tf --tail="50" "$@"'
DOCKER_CONFIG_DIR=/opt/docker_config


##############################
## BFUNK
##############################
export dd1=/srv/dev-disk-by-label-media_center/
export dd2=/srv/dev-disk-by-id-ata-WDC_WD15EADS-00P8B0_WD-WMAVU0549888-part1/
alias myip='dig +short myip.opendns.com @resolver1.opendns.com'
#alias start_vpn_torrent='sudo systemctl start vpn_access.service; sudo service transmission-daemon start; myip'
#alias stop_vpn_torrent='sudo service transmission-daemon stop; sudo systemctl stop vpn_access.service; myip'
#alias nginx_maintenance='sudo rm -f /etc/nginx/sites-enabled/* && sudo ln -s /etc/nginx/sites-available/omv_maintenance /etc/nginx/sites-enabled/omv_maintenance && sudo service nginx restart;'
#alias nginx_organizr='sudo rm -f /etc/nginx/sites-enabled/* && sudo ln -s /etc/nginx/sites-available/organizr /etc/nginx/sites-enabled/organizr && sudo service nginx restart;'
#alias filebot_movie_rename_dryrun='IFS=$(echo -en "\n\b"); for dir in `find -type d`; do filebot -rename $dir --db TheMovieDB --format "/export/torrent/{plex}" --action test; done'
#alias filebot_movie_rename_move='IFS=$(echo -en "\n\b"); for dir in `find -type d`; do filebot -rename $dir --db TheMovieDB --format "/export/torrent/{plex}" --action move; done'
#alias filebot_tvshows_rename_dryrun='filebot -rename -r -non-strict . --db TheTVDB --format "/export/torrent/{plex}" --action test'
#alias filebot_tvshows_rename_move='filebot -rename -r -non-strict . --db TheTVDB --format "/export/torrent/{plex}" --action move'

AIRSONIC_DATA_DIR=$DOCKER_CONFIG_DIR/airsonic
NEXCTLOUD_DATA_DIR=/export/nexctloud
alias backup_airsonic='sudo service airsonic stop && tar -cvf "/tmp/airsonic_$(date +%F_%R).tar" /var/airsonic && sudo service airsonic restart'
alias backup_nextcloud='sudo docker stop nextcloud && tar -cvf "/tmp/nextcloud_$(date +%F_%R).tar" $NEXCTLOUD_DATA_DIR &&; sudo docker start service nextcloud'

# when files are copied manually to nextcloud folder
alias nextcloud_force_rescan='docker exec nextcloud sudo -u abc php /config/www/nextcloud/occ files:scan --all'

